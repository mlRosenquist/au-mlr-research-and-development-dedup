This paper looked into performing anomaly detection on compressed data. Generalized Deduplication was the compression algorithm of choice, that enables direct analysis of the bases derived from the transformed data. The amount of compression controlled the clustering and performance of the anomaly detection models. The duplicates created by the algorithm is taken advantage of in an extended version of Isolation Forest. Comparing the proposed model with original Isolation Forest it showed that utilizing the duplicates improves classification performance. However, the improved scoring is a trade-off with memory usage and execution time. A general observation is that performing Isolation Forest on the uncompressed data versus compressed had no large discrepancies in performance.    